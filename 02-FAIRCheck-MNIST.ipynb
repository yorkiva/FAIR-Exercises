{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95351c2a",
   "metadata": {},
   "source": [
    "# Exploring MNIST dataset\n",
    "\n",
    "In the previous notebook, the very basics of the FAIR principles have been introduced. Now we would like to perform an exercise of evaluating the FAIRness of a popular dataset. For this purpose, we are going to explore the MNIST handwritten digits dataset.\n",
    "\n",
    "This dataset contains a total of 70,000 greyscale images of handwritted digits. Using the MNIST dataset is like the _Hello World_ of AI problems. All images are of 28 x 28 pixels in size. 60,000 of these images are usually identified as training data and the remaining 10,000 are test data. Let's explore the dataset and some of its content first. We will use the **PyTorch** package to get the data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "!mkdir -p data\n",
    "\n",
    "data_dir = \"data\"\n",
    "train_dataset = datasets.MNIST(data_dir, \n",
    "                               train=True, \n",
    "                               download=True,\n",
    "                               transform=transforms.ToTensor()\n",
    "                               )\n",
    "test_dataset = datasets.MNIST(data_dir, \n",
    "                              train=False, \n",
    "                              download=True,\n",
    "                              transform=transforms.ToTensor() \n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85875a",
   "metadata": {},
   "source": [
    "When one runs the code for the first time, it shows log messages like the following:\n",
    "\n",
    "`Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
    "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
    "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
    "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw`\n",
    "\n",
    "As one can see, these datasets are downloaded from the website <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>. If you explore the website, you can find the following compressed ubyte files that store this data:\n",
    "\n",
    "- train-images-idx3-ubyte.gz:  training set images (9912422 bytes)\n",
    "- train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)\n",
    "- t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)\n",
    "- t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes) \n",
    "\n",
    "In fact, you can use the corresponding URLs to download your data and then use the PyTorch DataLoader to obtain them in tensor format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39c7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-29 11:40:24--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:3036::ac43:ab4c, 2606:4700:3034::6815:1d24, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:3036::ac43:ab4c|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘data/MNIST/raw/train-images-idx3-ubyte.gz’\n",
      "\n",
      "train-images-idx3-u 100%[===================>]   9.45M  38.8MB/s    in 0.2s    \n",
      "\n",
      "2021-10-29 11:40:25 (38.8 MB/s) - ‘data/MNIST/raw/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
      "\n",
      "--2021-10-29 11:40:25--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:3036::ac43:ab4c, 2606:4700:3034::6815:1d24, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:3036::ac43:ab4c|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘data/MNIST/raw/train-labels-idx1-ubyte.gz’\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-29 11:40:25 (329 MB/s) - ‘data/MNIST/raw/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
      "\n",
      "--2021-10-29 11:40:25--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:3036::ac43:ab4c, 2606:4700:3034::6815:1d24, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:3036::ac43:ab4c|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/x-gzip]\n",
      "Saving to: ‘data/MNIST/raw/t10k-images-idx3-ubyte.gz’\n",
      "\n",
      "t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2021-10-29 11:40:25 (25.2 MB/s) - ‘data/MNIST/raw/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
      "\n",
      "--2021-10-29 11:40:25--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 2606:4700:3036::ac43:ab4c, 2606:4700:3034::6815:1d24, 172.67.171.76, ...\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|2606:4700:3036::ac43:ab4c|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/x-gzip]\n",
      "Saving to: ‘data/MNIST/raw/t10k-labels-idx1-ubyte.gz’\n",
      "\n",
      "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-29 11:40:25 (396 MB/s) - ‘data/MNIST/raw/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf data/MNIST/raw/*\n",
    "!wget -P data/MNIST/raw http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!wget -P data/MNIST/raw http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget -P data/MNIST/raw http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!wget -P data/MNIST/raw http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "!gunzip -k data/MNIST/raw/*gz\n",
    "\n",
    "train_dataset = datasets.MNIST(data_dir, \n",
    "                               train=True, \n",
    "                               download=False,\n",
    "                               transform=transforms.ToTensor()\n",
    "                               )\n",
    "test_dataset = datasets.MNIST(data_dir, \n",
    "                              train=False, \n",
    "                              download=False,\n",
    "                              transform=transforms.ToTensor() \n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031ba84",
   "metadata": {},
   "source": [
    "Note that we used `wget` to manually download the files and then uncompressed them using `gunzip`. The PyTorch DataLoader reads these files and prepares them in a way so that they can be readily used for training within the pyTorch framework. \n",
    "\n",
    "Now we can play around a little with these datasets to see what is in them and how they are structured. First, we can see how many entries we have in each of the training and test datasets, and how individual entries are structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "615c80c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training data: 60000\n",
      "Number of images in Test data: 10000\n",
      "\n",
      "\n",
      "Data type of individual entries: <class 'tuple'>\n",
      "Number of entries within each individual entry: 2\n",
      "\n",
      "\n",
      "Data type of entry 0: <class 'torch.Tensor'>\n",
      "Entry 0 is a tensor of shape: [1, 28, 28]\n",
      "Data type of entry 1: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in Training data: {}\".format(len(train_dataset)))\n",
    "print(\"Number of images in Test data: {}\".format(len(test_dataset)))\n",
    "print(\"\\n\")\n",
    "print(\"Data type of individual entries: {}\".format(type(train_dataset[0])))\n",
    "print(\"Number of entries within each individual entry: {}\".format(len(train_dataset[0])))\n",
    "print(\"\\n\")\n",
    "for ii in range(len(train_dataset[0])):\n",
    "    print(\"Data type of entry {}: {}\".format(ii, type(train_dataset[0][ii])))\n",
    "    if type(train_dataset[0][ii]) == torch.Tensor:\n",
    "        print(\"Entry {} is a tensor of shape: {}\".format(ii, list(train_dataset[0][ii].shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205878e",
   "metadata": {},
   "source": [
    "As we can see, the training and test datasets respectively have 60000 and 10000 entries where each entry is a tuple object of size 2. The first of these is a tensor object of shape $1 \\times 28 \\times 28$ and the second is an integer. At this point, we can probably guess that the first object is probably a grayscale $28 \\times 28$ image. A color image typically has a size of $3\\times M\\times N$ (for RGB encoding) or $4\\times M\\times N$ (for CMYK encoding), where $M$ and $N$ represent the pixel size in each dimension. The second object, being an integer, is probably the label of the image, telling us which digit the image represents. \n",
    "\n",
    "Let's visualize one such entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eee7b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of the image: 5\n",
      "Showing the image:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f50b5e79310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Label of the image: {}\".format(train_dataset[0][1]))\n",
    "print(\"Showing the image:\")\n",
    "plt.imshow(train_dataset[0][0].reshape(28,28).numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb21c97",
   "metadata": {},
   "source": [
    "# FAIRness Evaluation of MNIST dataset\n",
    "\n",
    "Now, we can start exploring how this dataset measures according to the FAIR metrics we already introduced in the previous notebook. \n",
    "\n",
    "## Findability\n",
    "\n",
    "_F1. (Meta)data are assigned a globally unique and persistent identifier_\n",
    "\n",
    "The identifier associated with the MNIST dataset is essentially the URL of the hosting web server: <a href=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a>. This is clearly unique but not necessarily persistent as webpages are prone to deprecation when domain names are lost or restructured.\n",
    "\n",
    "**Assessment of uniqueness: Pass <br/>\n",
    "Assessment of persistence: Fail**\n",
    "\n",
    "_F2. Data are described with rich metadata_\n",
    "\n",
    "The metadata of this dataset is essentially described by a block of text and  no persistent identifier for metadata is provided. The textual description provides enough details of how the dataset was constructed and the content and format of these datasets.\n",
    "\n",
    "**Assessment of machine readability of metadata: Fail <br/>**\n",
    "**Assessment of richness of metadata: Pass**\n",
    "\n",
    "_F3. Metadata clearly and explicitly include the identifier of the data they describe_\n",
    "\n",
    "The textual description does not include the dataset identifier, the URL used to access this dataset.\n",
    "\n",
    "**Assessment: Fail**\n",
    "\n",
    "_F4. (Meta)data are registered or indexed in a searchable resource_\n",
    "\n",
    "Given the widespread use of the MNIST dataset, it is simple to find via quick web searches. Searching in Google Dataset Search reveals multiple indexed instances of the MNIST dataset that are derived and rehosted by other communities like <a href=\"https://www.kaggle.com/hojjatk/mnist-dataset\">Kaggle</a> and <a href=\"https://deepai.org/dataset/mnist\">DeepAI</a>. However, the original dataset is not readily found via the dataset search.\n",
    "\n",
    "**Assessment: Partially Pass**\n",
    "\n",
    "## Accessibility\n",
    "\n",
    "_A1. (Meta)data are retrievable by their identifier using a standardised communications protocol_\n",
    "\n",
    "The MNIST dataset is an open dataset, and can be accessed via standard HTTP protocol.\n",
    "\n",
    "**Assessment: Pass**\n",
    "\n",
    "_A2. Metadata are accessible, even when the data are no longer available_\n",
    "\n",
    "As the metadata is hosted by the same webpage and does not come with its own unique and persistent identifier, it may be difficult to retrieve the metadata if the dataset is lost.\n",
    "\n",
    "**Assessment: Fail**\n",
    "\n",
    "## Interoperability\n",
    "\n",
    "_I1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation_\n",
    "\n",
    "The metadata comes with elaborate explanation of the format. The files are essentially in binary format with certain information about its organization explained in the metadata.\n",
    "\n",
    "**Assessment: Pass**\n",
    "\n",
    "_I2. (Meta)data use vocabularies that follow FAIR principles_\n",
    "\n",
    "The metadata is descriptive but certain items that it describe don't follow the FAIR principles themselves. For instance, the IDX file format used to present the data has been described but it does not come with a unique identifier or accessible metadata for this format.\n",
    "\n",
    "**Assessment: Partially Pass**\n",
    "\n",
    "_I3. (Meta)data include qualified references to other (meta)data_\n",
    "\n",
    "The documentation comes with a large number of references for application of this database for image classification programs. However, it does not provide references to the original datasets used to construct it, neither does it include any reference to the formatting used for the dataset.\n",
    "\n",
    "**Assessment: Fail**\n",
    "\n",
    "## Reusability\n",
    "\n",
    "_R1.1. (Meta)data are released with a clear and accessible data usage license_\n",
    "\n",
    "The documentation does not clearly specify any license field.\n",
    "\n",
    "**Assessment: Fail**\n",
    "\n",
    "_R1.2. (Meta)data are associated with detailed provenance_\n",
    "\n",
    "Metadata explains how this dataset was created using other larger datasets. It also explains how the images are formatted.\n",
    "\n",
    "**Assessment: Pass**\n",
    "\n",
    "_R1.3. (Meta)data meet domain-relevant community standards_\n",
    "\n",
    "Being a widely used dataset for computer vision and image recognition tasks, the metadata provides adequate details about its content, format and representation.\n",
    "\n",
    "**Assessment: Pass**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65631b08",
   "metadata": {},
   "source": [
    "# Interpreting the FAIRness Evaluation\n",
    "\n",
    "One can ask- what's all the fuss for? MNIST is a well established and widely used dataset and who cares if it does not follow some customized set of metrics.\n",
    "\n",
    "We can see that even a widely used database like MNIST fails a number of FAIRness tests. MNIST is a relatively small and simple dataset with widespread use across multiple communities. It also has served as the go-to pedagogical example for introduction to neural networks and deep learning. However, such might not be the case for other datasets. Practical datasets are often quite large, tabular datasets requiring TBs of disk space comprising hundreds of features are not uncommon these days. Without establishing the FAIRness of such datasets, reusing them for reproducing results and further research might be a nightmare scenario. Machine readability of metadata is also particularly useful when one wants to organize and manage these datasets in an automated fashion. \n",
    "\n",
    "As we have seen in the case of MNIST, most of its _failure_ cases emerge from having no machine readable metadata. This is probably understandable, since the standards and frameworks machine readable metadat are relatively new while the dataset has been around for about two decades now. However, for domain specific complex and modern datasets, abiding by the FAIR rules is absolutely essential to ensure their faithful resuability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
